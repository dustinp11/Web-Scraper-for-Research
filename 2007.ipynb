{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431fb620-7aac-497a-975c-1902706a7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3698a45-05aa-49c9-bd24-62ed4e7f135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_day(formatted_date):\n",
    "    # Parse the formatted date\n",
    "    date_obj = datetime.strptime(formatted_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Calculate the previous date\n",
    "    previous_date = date_obj - timedelta(days=1)\n",
    "    \n",
    "    # Return only the day of the previous date\n",
    "    previous_day = previous_date.day\n",
    "    return previous_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "802d7dd3-649b-4a04-9cf2-f0586c27e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver\n",
    "def accept_cookies(driver):\n",
    "    \"\"\"Accepts cookies when prompted, used after a new driver is open.\"\"\"\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        accept_button = driver.find_element(By.ID, \"onetrust-accept-btn-handler\")\n",
    "        accept_button.click()\n",
    "        time.sleep(1)  # Pause to allow the click to register\n",
    "    except Exception as e:\n",
    "        print(f\"Cookie acceptance button not found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e63bcd-485e-4d56-8f77-d7a31a6a9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(res, year):\n",
    "    \"\"\"Sorts and writes the current data to csv.\"\"\"\n",
    "    df = pd.DataFrame(res, columns=['year', 'team', 'games', 'date', 'wins', 'losses', 'WCGB'])\n",
    "\n",
    "    # Sort the DataFrame\n",
    "    df_sorted = df.sort_values(by=['year', 'team', 'games'])\n",
    "        \n",
    "    path = f\"L:/RA_work/JAY/datasets/final/non_finalcopies/{year}.csv\"\n",
    "    df_sorted.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfa5621c-913a-45bd-9840-e28fbefc5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html(year, date, driver):\n",
    "    \"\"\"\n",
    "    Extracts data from a main table.\n",
    "\n",
    "    Args:\n",
    "        year (int): The year for which the data is being extracted.\n",
    "        date (str): The date for which the data is being extracted.\n",
    "        driver (WebDriver): The Selenium WebDriver instance.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted data rows, where each row contains information about a team, game stats, and the specified date.\n",
    "    \"\"\"\n",
    "    total = []\n",
    "    try:\n",
    "        \n",
    "        main_table = driver.find_element(By.CLASS_NAME, \"tablestyle__StyledTable-sc-wsl6eq-0\")\n",
    "        \n",
    "        \n",
    "        if not main_table:\n",
    "            raise ValueError(\"Main table with class 'tablestyle__StyledTable-sc-wsl6eq-0' not found.\")\n",
    "        \n",
    "        # Find all tbody elements within the main table\n",
    "        tbodies = main_table.find_elements(By.TAG_NAME, \"tbody\")\n",
    "        \n",
    "        # These indices are which tbody elements contain info (the others are headers)\n",
    "        indices_to_extract = [0, 2, 4, 6, 8, 10]\n",
    "        \n",
    "        for index in indices_to_extract:\n",
    "            \n",
    "            if index < len(tbodies):\n",
    "                tbody = tbodies[index]\n",
    "                \n",
    "                rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "                \n",
    "                for row in rows:\n",
    "                    # Get team name from th\n",
    "                    th = row.find_element(By.TAG_NAME, \"th\")\n",
    "                    team_name = th.find_element(By.TAG_NAME, \"a\").text\n",
    "                    \n",
    "                    # Get remaining row data\n",
    "                    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                    cell_text = [cell.text for cell in cells]\n",
    "                    game = int(cell_text[0]) + int(cell_text[1]) + 1\n",
    "                    output = [year, team_name, game, date, cell_text[0], cell_text[1], cell_text[4]]\n",
    "                    print(output)\n",
    "                    # Print the team name and row data for debugging purposes\n",
    "                    total.append(output)\n",
    "            else:\n",
    "                print(f\"Tbody index {index} is out of range.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in read_html: {str(e)}\")\n",
    "    finally:\n",
    "        return total\n",
    "\n",
    "\n",
    "\n",
    "def run(year, driver):\n",
    "    \"\"\"\n",
    "    Loads and parses through mlb site to get data for a particular year. (Each year has a separate URL)\n",
    "\n",
    "    Args:\n",
    "        year (int): The year for which the data is being retrieved.\n",
    "        driver (WebDriver): The Selenium WebDriver instance.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of all extracted data rows across all selected dates in the year.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    driver.get(f\"https://www.mlb.com/standings/{year}\")\n",
    "    accept_cookies(driver)\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        \n",
    "        def select_menu():\n",
    "            \"\"\"Opens and selects the calendar menu.\"\"\"\n",
    "            date_picker_input = wait.until(EC.visibility_of_element_located((By.ID, \"pickerInput\")))\n",
    "    \n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", date_picker_input)\n",
    "    \n",
    "            try:\n",
    "                date_picker_input.click()\n",
    "            except Exception as e:\n",
    "                driver.execute_script(\"arguments[0].click();\", date_picker_input)\n",
    "\n",
    "      \n",
    "        def tail():\n",
    "            \"\"\"Interacts with the button used to select date after the calendar is open, then writes current data to csv.\"\"\"\n",
    "            date_label = driver.find_element(By.CLASS_NAME, \"datePickerstyle__DateLabel-sc-1ewrv5d-8\")\n",
    "            current_date = date_label.text\n",
    "            _, month_name, day = current_date.split()\n",
    "            month_number = datetime.strptime(month_name, \"%b\").month\n",
    "            formatted_date = f\"{year}-{month_number:02d}-{int(day):02d}\"\n",
    "            print(f\"Current date: {formatted_date}\")\n",
    "            \n",
    "            res.extend(read_html(year, formatted_date, driver)) # Getting the stats\n",
    "            to_csv(res, year)\n",
    "            # Get the currently selected day\n",
    "            selected_day_element = driver.find_element(By.CLASS_NAME, \"react-datepicker__day--selected\")\n",
    "            selected_day = selected_day_element.text\n",
    "            day_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"react-datepicker__day\")))\n",
    "            \n",
    "            # Attempt to find and click the previous day\n",
    "            previous_day_element = None\n",
    "            day_text = None\n",
    "            \n",
    "            for i, j in enumerate(day_elements):\n",
    "                # If the first days that appear are disabled, do not set previous_day_element\n",
    "                if j.get_attribute(\"aria-disabled\") == \"true\":\n",
    "                    continue\n",
    "                elif j.get_attribute(\"aria-selected\") == \"true\":\n",
    "                    # If we reach the selected element stop the loop and keep previous element\n",
    "                    # Must check if the selected element is the first to appear \n",
    "                    if i == 0:\n",
    "                        prev_month_button = driver.find_element(By.XPATH, \"//button[@aria-label='Previous Month']\")\n",
    "                        if prev_month_button.is_enabled():\n",
    "                            prev_month_button.click()\n",
    "                            time.sleep(0.2)\n",
    "                            day_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"react-datepicker__day\")))\n",
    "                            last_day = day_elements[-1]\n",
    "                            last_day.click()\n",
    "                            return get_previous_day(formatted_date)\n",
    "                        else:\n",
    "                            print(\"No more previous months available.\")  \n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                previous_day_element = j\n",
    "                day_text = j.text\n",
    "        \n",
    "            if previous_day_element:\n",
    "                previous_day_element.click()\n",
    "                time.sleep(0.2)\n",
    "                return day_text\n",
    "            else:\n",
    "                print(\"No selectable previous day found\")\n",
    "                return None\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        def select_menu():\n",
    "            date_picker_input = wait.until(EC.visibility_of_element_located((By.ID, \"pickerInput\")))\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", date_picker_input)\n",
    "            try:\n",
    "                date_picker_input.click()\n",
    "            except Exception as e:\n",
    "                driver.execute_script(\"arguments[0].click();\", date_picker_input)\n",
    "\n",
    "        select_menu()\n",
    "        last_day = tail()\n",
    "        stop = 0\n",
    "        while last_day: \n",
    "            time.sleep(6)\n",
    "            select_menu()\n",
    "            last_day = tail()\n",
    "            stop += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {str(e)}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf10f4-47c1-42eb-8e5d-76f019e78c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to start\n",
    "# Edit buffer size to determine how many years will be scraped at once\n",
    "nest_asyncio.apply()\n",
    "async def process_batch(batch):\n",
    "    with ThreadPoolExecutor(max_workers=len(batch)) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        \n",
    "        tasks = [loop.run_in_executor(executor, run, year, webdriver.Chrome()) for year, _ in batch]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    temp = [(x, f\"https://www.mlb.com/standings/wild-card/{x}\") for x in range(2011, 2014)]\n",
    "    batch_size = 3\n",
    "\n",
    "    for i in range(0, len(temp), batch_size):\n",
    "        batch = temp[i:i + batch_size]\n",
    "        await process_batch(batch)\n",
    "\n",
    "# Run the async main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f53f0a-760d-4e62-ae63-3ceb120cb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_game_data(files):\n",
    "    # Merge and sort data\n",
    "    dataframes = [pd.read_csv(file) for file in files]\n",
    "    merged_df = pd.concat(dataframes)\n",
    "    merged_df = merged_df.sort_values(by=['year', 'team', 'games']).reset_index(drop=True)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    merged_df = merged_df.drop_duplicates(subset=['year', 'team', 'games'])\n",
    "    \n",
    "    # Add buffer rows\n",
    "    buffer_rows = []\n",
    "    grouped = merged_df.groupby(['year', 'team'])\n",
    "    \n",
    "    for (year, team), group in grouped:\n",
    "        min_game = group['games'].min()\n",
    "        max_game = group['games'].max()\n",
    "        existing_games = set(group['games'])\n",
    "        \n",
    "        # Find missing games and add buffer rows\n",
    "        for game in range(min_game, max_game + 1):\n",
    "            if game not in existing_games:\n",
    "                buffer_rows.append([year, team, game, '', '', '', ''])\n",
    "    \n",
    "    \n",
    "    buffer_df = pd.DataFrame(buffer_rows, columns=merged_df.columns)\n",
    "    final_df = pd.concat([merged_df, buffer_df]).sort_values(by=['year', 'team', 'games']).reset_index(drop=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "files = [\"L:/RA_work/JAY/datasets/final/non_finalcopies/\" + str(x) + \".csv\" for x in range(2007, 2014)]\n",
    "final_df = process_game_data(files)\n",
    "\n",
    "final_df.to_csv(\"L:/RA_work/JAY/datasets/final/non_finalcopies/merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16548fec-53df-487b-81d4-e6abbb1cb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_plus():\n",
    "    df = pd.read_csv(\"L:/RA_work/JAY/datasets/final/non_finalcopies/merged.csv\")\n",
    "\n",
    "    df['WCGB'] = df['WCGB'].astype(str).str.replace('+', 'up ', regex=False)\n",
    "    \n",
    "    df.to_csv(\"L:/RA_work/JAY/datasets/final/non_finalcopies/final2007to2013.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11d59aa-122e-4415-8fa9-7b55d1bb1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dash():\n",
    "    df = pd.read_csv(\"L:/RA_work/JAY/datasets/final/non_finalcopies/final2007to2013.csv\")\n",
    "    df['WCGB'] = df['WCGB'].astype(str).str.replace('+', 'up ', regex=False)\n",
    "    df['WCGB'] = df['WCGB'].replace('nan', ' ')\n",
    "    \n",
    "    df.to_csv(\"L:/RA_work/JAY/datasets/final/non_finalcopies/playoff_odds_2007to2013.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
